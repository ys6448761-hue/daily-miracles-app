# ğŸš€ MCP Part 2-5 ì™„ì„± ì§€ì‹œì„œ
## Code ì¦‰ì‹œ ì‹¤í–‰ìš© - 2-3ì¼ ì™„ì„± í”„ë¡œì íŠ¸

> **ëŒ€ìƒ:** Claude Code (ê¸°ìˆ  ì‹¤í–‰)  
> **ì‘ì„±:** ì½”ë¯¸ (ì´ê´„ ë§¤ë‹ˆì €)  
> **ëª©í‘œ:** MCP 33% â†’ 100% ì™„ì„±  
> **ê¸°í•œ:** 2-3ì¼

---

## ğŸ“Š í˜„ì¬ ìƒí™©

### âœ… ì™„ë£Œ (Part 1)
```
mcp-servers/
â”œâ”€â”€ miracle-mcp/         âœ… ì™„ë£Œ
â”œâ”€â”€ wishmaker-hub-mcp/   âœ… ì™„ë£Œ
â””â”€â”€ summarizer-mcp/      âœ… ì™„ë£Œ
```

### â³ ë‚¨ì€ ì‘ì—… (Part 2-5)
```
mcp-servers/
â”œâ”€â”€ business-ops-mcp/    â³ ìƒˆë¡œ ìƒì„±
â”œâ”€â”€ tech-monitor-mcp/    â³ ìƒˆë¡œ ìƒì„±
â”œâ”€â”€ ceo-checklist-mcp/   â³ ìƒˆë¡œ ìƒì„±
â””â”€â”€ dashboard-mcp/       â³ ìƒˆë¡œ ìƒì„±
```

---

## ğŸ“… 3ì¼ ì¼ì •

### Day 1: Part 2 (ë¹„ì¦ˆë‹ˆìŠ¤ ìš´ì˜)
```
ì˜¤ì „:
- business-ops-mcp í´ë” ìƒì„±
- ê²°ì œ ì¡°íšŒ ë„êµ¬ êµ¬í˜„
- ë§¤ì¶œ ë¶„ì„ ë„êµ¬ êµ¬í˜„

ì˜¤í›„:
- êµ¬ë… í˜„í™© ë„êµ¬ êµ¬í˜„
- í…ŒìŠ¤íŠ¸
- Desktop ì—°ë™
```

### Day 2: Part 3-4 (ì¸í”„ë¼ + ì²´í¬ë¦¬ìŠ¤íŠ¸)
```
ì˜¤ì „:
- tech-monitor-mcp ì™„ì„±
  (ì„œë²„/DB/API ëª¨ë‹ˆí„°)

ì˜¤í›„:
- ceo-checklist-mcp ì™„ì„±
  (í‘¸ë¥´ë¯¸ë¥´ë‹˜ í•  ì¼)
```

### Day 3: Part 5 (í†µí•© ëŒ€ì‹œë³´ë“œ)
```
ì˜¤ì „:
- dashboard-mcp ì™„ì„±
  (ì „ì²´ í†µí•©)

ì˜¤í›„:
- í†µí•© í…ŒìŠ¤íŠ¸
- ë¬¸ì„œ ì‘ì„±
- 100% ì™„ì„±! ğŸ‰
```

---

## ğŸ”§ Part 2: Business Operations MCP

### í´ë” ìƒì„±

```bash
cd "C:\Users\ì„¸ì§„\OneDrive\ë°”íƒ• í™”ë©´\daily-miracles-mvp\mcp-servers"
mkdir business-ops-mcp
cd business-ops-mcp
```

### pyproject.toml

```toml
[project]
name = "business-ops-mcp"
version = "0.1.0"
description = "ë¹„ì¦ˆë‹ˆìŠ¤ ìš´ì˜ MCP - ê²°ì œ, ë§¤ì¶œ, êµ¬ë… ê´€ë¦¬"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "mcp>=1.1.2",
    "psycopg2-binary>=2.9.10",
    "python-dotenv>=1.0.0"
]

[project.scripts]
business-ops-mcp = "business_ops_mcp:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

### src/business_ops_mcp/__init__.py

```python
"""
Business Operations MCP Server
ê²°ì œ, ë§¤ì¶œ, êµ¬ë… ê´€ë¦¬
"""

import os
import json
from datetime import datetime, timedelta
from typing import Any
import asyncio

import psycopg2
from psycopg2.extras import RealDictCursor
from dotenv import load_dotenv

from mcp.server.models import InitializationOptions
from mcp.server import NotificationOptions, Server
from mcp.server.stdio import stdio_server
from mcp.types import (
    Tool,
    TextContent,
    ImageContent,
    EmbeddedResource,
)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# DB ì—°ê²°
def get_db_connection():
    """PostgreSQL ì—°ê²°"""
    return psycopg2.connect(
        os.getenv("DATABASE_URL"),
        cursor_factory=RealDictCursor
    )

# ì„œë²„ ìƒì„±
server = Server("business-ops-mcp")

@server.list_tools()
async def handle_list_tools() -> list[Tool]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡"""
    return [
        Tool(
            name="get_payments",
            description="ê²°ì œ ë‚´ì—­ ì¡°íšŒ (ê¸°ê°„ë³„, ìƒíƒœë³„)",
            inputSchema={
                "type": "object",
                "properties": {
                    "days": {
                        "type": "number",
                        "description": "ìµœê·¼ Nì¼ (ê¸°ë³¸: 7ì¼)",
                        "default": 7
                    },
                    "status": {
                        "type": "string",
                        "description": "ê²°ì œ ìƒíƒœ (all/completed/pending/failed)",
                        "enum": ["all", "completed", "pending", "failed"],
                        "default": "all"
                    }
                }
            }
        ),
        Tool(
            name="get_revenue",
            description="ë§¤ì¶œ í†µê³„ ë¶„ì„ (ì¼ë³„, ì£¼ë³„, ì›”ë³„)",
            inputSchema={
                "type": "object",
                "properties": {
                    "period": {
                        "type": "string",
                        "description": "ë¶„ì„ ê¸°ê°„ (daily/weekly/monthly)",
                        "enum": ["daily", "weekly", "monthly"],
                        "default": "daily"
                    },
                    "days": {
                        "type": "number",
                        "description": "ìµœê·¼ Nì¼",
                        "default": 30
                    }
                }
            }
        ),
        Tool(
            name="get_subscriptions",
            description="êµ¬ë… í˜„í™© ê´€ë¦¬ (í™œì„±/ë§Œë£Œ/ì·¨ì†Œ)",
            inputSchema={
                "type": "object",
                "properties": {
                    "status": {
                        "type": "string",
                        "description": "êµ¬ë… ìƒíƒœ",
                        "enum": ["all", "active", "expired", "cancelled"],
                        "default": "all"
                    }
                }
            }
        ),
        Tool(
            name="get_revenue_forecast",
            description="ë§¤ì¶œ ì˜ˆì¸¡ (ë‹¤ìŒ ë‹¬ ì˜ˆìƒ ë§¤ì¶œ)",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        )
    ]

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict | None) -> list[TextContent]:
    """ë„êµ¬ ì‹¤í–‰"""
    
    if arguments is None:
        arguments = {}
    
    try:
        if name == "get_payments":
            result = get_payments(
                days=arguments.get("days", 7),
                status=arguments.get("status", "all")
            )
            
        elif name == "get_revenue":
            result = get_revenue(
                period=arguments.get("period", "daily"),
                days=arguments.get("days", 30)
            )
            
        elif name == "get_subscriptions":
            result = get_subscriptions(
                status=arguments.get("status", "all")
            )
            
        elif name == "get_revenue_forecast":
            result = get_revenue_forecast()
            
        else:
            raise ValueError(f"Unknown tool: {name}")
        
        return [TextContent(
            type="text",
            text=json.dumps(result, ensure_ascii=False, indent=2)
        )]
        
    except Exception as e:
        return [TextContent(
            type="text",
            text=f"Error: {str(e)}"
        )]

def get_payments(days: int = 7, status: str = "all") -> dict:
    """ê²°ì œ ë‚´ì—­ ì¡°íšŒ"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    # ë‚ ì§œ ê³„ì‚°
    start_date = datetime.now() - timedelta(days=days)
    
    # ì¿¼ë¦¬
    query = """
        SELECT 
            id,
            user_id,
            amount,
            status,
            payment_method,
            paid_at,
            created_at
        FROM payments
        WHERE created_at >= %s
    """
    
    params = [start_date]
    
    if status != "all":
        query += " AND status = %s"
        params.append(status)
    
    query += " ORDER BY created_at DESC"
    
    cur.execute(query, params)
    payments = cur.fetchall()
    
    # í†µê³„
    total_amount = sum(p['amount'] for p in payments if p['status'] == 'completed')
    total_count = len(payments)
    completed_count = sum(1 for p in payments if p['status'] == 'completed')
    
    cur.close()
    conn.close()
    
    return {
        "period": f"ìµœê·¼ {days}ì¼",
        "total_count": total_count,
        "completed_count": completed_count,
        "total_amount": total_amount,
        "payments": [
            {
                "id": p['id'],
                "user_id": p['user_id'],
                "amount": p['amount'],
                "status": p['status'],
                "method": p['payment_method'],
                "paid_at": p['paid_at'].isoformat() if p['paid_at'] else None,
                "created_at": p['created_at'].isoformat()
            }
            for p in payments
        ]
    }

def get_revenue(period: str = "daily", days: int = 30) -> dict:
    """ë§¤ì¶œ í†µê³„"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    start_date = datetime.now() - timedelta(days=days)
    
    if period == "daily":
        group_by = "DATE(paid_at)"
        date_format = "YYYY-MM-DD"
    elif period == "weekly":
        group_by = "DATE_TRUNC('week', paid_at)"
        date_format = "YYYY-WW"
    else:  # monthly
        group_by = "DATE_TRUNC('month', paid_at)"
        date_format = "YYYY-MM"
    
    query = f"""
        SELECT 
            {group_by} as period,
            COUNT(*) as count,
            SUM(amount) as revenue
        FROM payments
        WHERE paid_at >= %s
        AND status = 'completed'
        GROUP BY {group_by}
        ORDER BY {group_by} DESC
    """
    
    cur.execute(query, [start_date])
    results = cur.fetchall()
    
    total_revenue = sum(r['revenue'] for r in results)
    total_count = sum(r['count'] for r in results)
    avg_per_transaction = total_revenue / total_count if total_count > 0 else 0
    
    cur.close()
    conn.close()
    
    return {
        "period_type": period,
        "total_revenue": total_revenue,
        "total_transactions": total_count,
        "avg_per_transaction": round(avg_per_transaction, 2),
        "breakdown": [
            {
                "period": r['period'].isoformat() if hasattr(r['period'], 'isoformat') else str(r['period']),
                "count": r['count'],
                "revenue": r['revenue']
            }
            for r in results
        ]
    }

def get_subscriptions(status: str = "all") -> dict:
    """êµ¬ë… í˜„í™©"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    # í˜„ì¬ ì‹œê°„
    now = datetime.now()
    
    query = """
        SELECT 
            id,
            user_id,
            plan_type,
            status,
            start_date,
            end_date,
            auto_renew,
            created_at
        FROM subscriptions
    """
    
    if status != "all":
        query += " WHERE status = %s"
        cur.execute(query, [status])
    else:
        cur.execute(query)
    
    subs = cur.fetchall()
    
    # ë¶„ë¥˜
    active = [s for s in subs if s['status'] == 'active']
    expired = [s for s in subs if s['status'] == 'expired']
    cancelled = [s for s in subs if s['status'] == 'cancelled']
    
    # ê³§ ë§Œë£Œ (7ì¼ ì´ë‚´)
    expiring_soon = [
        s for s in active 
        if s['end_date'] and (s['end_date'] - now).days <= 7
    ]
    
    cur.close()
    conn.close()
    
    return {
        "total": len(subs),
        "active": len(active),
        "expired": len(expired),
        "cancelled": len(cancelled),
        "expiring_soon": len(expiring_soon),
        "subscriptions": [
            {
                "id": s['id'],
                "user_id": s['user_id'],
                "plan": s['plan_type'],
                "status": s['status'],
                "start": s['start_date'].isoformat() if s['start_date'] else None,
                "end": s['end_date'].isoformat() if s['end_date'] else None,
                "auto_renew": s['auto_renew']
            }
            for s in subs
        ]
    }

def get_revenue_forecast() -> dict:
    """ë§¤ì¶œ ì˜ˆì¸¡"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    # ìµœê·¼ 30ì¼ ë§¤ì¶œ
    query = """
        SELECT SUM(amount) as total
        FROM payments
        WHERE paid_at >= NOW() - INTERVAL '30 days'
        AND status = 'completed'
    """
    cur.execute(query)
    last_30_days = cur.fetchone()['total'] or 0
    
    # ì¼í‰ê· 
    daily_avg = last_30_days / 30
    
    # ë‹¤ìŒ ë‹¬ ì˜ˆì¸¡ (ì¼í‰ê·  * 30)
    next_month_forecast = daily_avg * 30
    
    # í™œì„± êµ¬ë… ê¸°ë°˜ ì˜ˆì¸¡
    query = """
        SELECT COUNT(*) as count, AVG(monthly_fee) as avg_fee
        FROM subscriptions
        WHERE status = 'active'
    """
    cur.execute(query)
    sub_data = cur.fetchone()
    
    active_subs = sub_data['count'] or 0
    avg_sub_fee = sub_data['avg_fee'] or 0
    
    subscription_forecast = active_subs * avg_sub_fee
    
    cur.close()
    conn.close()
    
    return {
        "forecast_date": (datetime.now() + timedelta(days=30)).strftime("%Y-%m"),
        "method_1": {
            "name": "ì¼í‰ê·  ê¸°ë°˜",
            "last_30_days": last_30_days,
            "daily_average": round(daily_avg, 2),
            "forecast": round(next_month_forecast, 2)
        },
        "method_2": {
            "name": "êµ¬ë… ê¸°ë°˜",
            "active_subscriptions": active_subs,
            "avg_monthly_fee": round(avg_sub_fee, 2),
            "forecast": round(subscription_forecast, 2)
        },
        "combined_forecast": round((next_month_forecast + subscription_forecast) / 2, 2)
    }

async def main():
    """ë©”ì¸ ì‹¤í–‰"""
    async with stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="business-ops-mcp",
                server_version="0.1.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                )
            )
        )

if __name__ == "__main__":
    asyncio.run(main())
```

### README.md

```markdown
# Business Operations MCP

ë¹„ì¦ˆë‹ˆìŠ¤ ìš´ì˜ MCP ì„œë²„

## ê¸°ëŠ¥

- `get_payments`: ê²°ì œ ë‚´ì—­ ì¡°íšŒ
- `get_revenue`: ë§¤ì¶œ í†µê³„ ë¶„ì„
- `get_subscriptions`: êµ¬ë… í˜„í™© ê´€ë¦¬
- `get_revenue_forecast`: ë§¤ì¶œ ì˜ˆì¸¡

## ì„¤ì¹˜

```bash
uv sync
```

## ì‹¤í–‰

```bash
uv run business-ops-mcp
```
```

---

## ğŸ”§ Part 3: Tech Monitor MCP

### í´ë” ìƒì„±

```bash
cd "C:\Users\ì„¸ì§„\OneDrive\ë°”íƒ• í™”ë©´\daily-miracles-mvp\mcp-servers"
mkdir tech-monitor-mcp
cd tech-monitor-mcp
```

### pyproject.toml

```toml
[project]
name = "tech-monitor-mcp"
version = "0.1.0"
description = "ê¸°ìˆ  ì¸í”„ë¼ ëª¨ë‹ˆí„°ë§ MCP"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "mcp>=1.1.2",
    "psycopg2-binary>=2.9.10",
    "python-dotenv>=1.0.0",
    "requests>=2.31.0"
]

[project.scripts]
tech-monitor-mcp = "tech_monitor_mcp:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

### src/tech_monitor_mcp/__init__.py

```python
"""
Tech Monitor MCP Server
ì„œë²„, DB, API ëª¨ë‹ˆí„°ë§
"""

import os
import json
from datetime import datetime
from typing import Any
import asyncio

import psycopg2
from psycopg2.extras import RealDictCursor
import requests
from dotenv import load_dotenv

from mcp.server.models import InitializationOptions
from mcp.server import NotificationOptions, Server
from mcp.server.stdio import stdio_server
from mcp.types import Tool, TextContent

load_dotenv()

def get_db_connection():
    return psycopg2.connect(
        os.getenv("DATABASE_URL"),
        cursor_factory=RealDictCursor
    )

server = Server("tech-monitor-mcp")

@server.list_tools()
async def handle_list_tools() -> list[Tool]:
    return [
        Tool(
            name="check_server_status",
            description="ì„œë²„ ìƒíƒœ ì ê²€ (Render ì•± ìƒíƒœ)",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        ),
        Tool(
            name="check_db_health",
            description="DB ê±´ê°•ë„ ì²´í¬ (ì—°ê²°, ì„±ëŠ¥, ìš©ëŸ‰)",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        ),
        Tool(
            name="check_api_performance",
            description="API ì„±ëŠ¥ ëª¨ë‹ˆí„° (ì‘ë‹µì‹œê°„, ì—ëŸ¬ìœ¨)",
            inputSchema={
                "type": "object",
                "properties": {
                    "hours": {
                        "type": "number",
                        "description": "ìµœê·¼ Nì‹œê°„",
                        "default": 24
                    }
                }
            }
        ),
        Tool(
            name="get_error_logs",
            description="ì—ëŸ¬ ë¡œê·¸ ì¡°íšŒ",
            inputSchema={
                "type": "object",
                "properties": {
                    "limit": {
                        "type": "number",
                        "description": "ìµœëŒ€ ê°œìˆ˜",
                        "default": 20
                    }
                }
            }
        )
    ]

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict | None) -> list[TextContent]:
    
    if arguments is None:
        arguments = {}
    
    try:
        if name == "check_server_status":
            result = check_server_status()
        elif name == "check_db_health":
            result = check_db_health()
        elif name == "check_api_performance":
            result = check_api_performance(arguments.get("hours", 24))
        elif name == "get_error_logs":
            result = get_error_logs(arguments.get("limit", 20))
        else:
            raise ValueError(f"Unknown tool: {name}")
        
        return [TextContent(
            type="text",
            text=json.dumps(result, ensure_ascii=False, indent=2)
        )]
    except Exception as e:
        return [TextContent(
            type="text",
            text=f"Error: {str(e)}"
        )]

def check_server_status() -> dict:
    """ì„œë²„ ìƒíƒœ ì²´í¬"""
    
    # Render ì•± URL
    app_url = os.getenv("APP_URL", "https://daily-miracles-app.onrender.com")
    
    try:
        response = requests.get(f"{app_url}/health", timeout=10)
        status = "healthy" if response.status_code == 200 else "unhealthy"
        response_time = response.elapsed.total_seconds()
    except Exception as e:
        status = "error"
        response_time = None
    
    return {
        "timestamp": datetime.now().isoformat(),
        "app_url": app_url,
        "status": status,
        "response_time_seconds": response_time,
        "checked_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }

def check_db_health() -> dict:
    """DB ê±´ê°•ë„"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    # ì—°ê²° í…ŒìŠ¤íŠ¸
    cur.execute("SELECT NOW()")
    db_time = cur.fetchone()
    
    # DB í¬ê¸°
    cur.execute("""
        SELECT pg_size_pretty(pg_database_size(current_database())) as size
    """)
    db_size = cur.fetchone()['size']
    
    # í™œì„± ì—°ê²° ìˆ˜
    cur.execute("""
        SELECT COUNT(*) as count
        FROM pg_stat_activity
        WHERE state = 'active'
    """)
    active_connections = cur.fetchone()['count']
    
    # í…Œì´ë¸” ê°œìˆ˜
    cur.execute("""
        SELECT COUNT(*) as count
        FROM information_schema.tables
        WHERE table_schema = 'public'
    """)
    table_count = cur.fetchone()['count']
    
    cur.close()
    conn.close()
    
    return {
        "status": "healthy",
        "db_size": db_size,
        "active_connections": active_connections,
        "table_count": table_count,
        "checked_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }

def check_api_performance(hours: int = 24) -> dict:
    """API ì„±ëŠ¥ ëª¨ë‹ˆí„°"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    # API ë¡œê·¸ê°€ ìˆë‹¤ë©´
    query = """
        SELECT 
            endpoint,
            COUNT(*) as requests,
            AVG(response_time) as avg_time,
            MAX(response_time) as max_time,
            COUNT(*) FILTER (WHERE status_code >= 400) as errors
        FROM api_logs
        WHERE created_at >= NOW() - INTERVAL '%s hours'
        GROUP BY endpoint
        ORDER BY requests DESC
    """
    
    try:
        cur.execute(query, [hours])
        results = cur.fetchall()
        
        total_requests = sum(r['requests'] for r in results)
        total_errors = sum(r['errors'] for r in results)
        error_rate = (total_errors / total_requests * 100) if total_requests > 0 else 0
        
        return {
            "period_hours": hours,
            "total_requests": total_requests,
            "total_errors": total_errors,
            "error_rate_percent": round(error_rate, 2),
            "endpoints": [
                {
                    "endpoint": r['endpoint'],
                    "requests": r['requests'],
                    "avg_time_ms": round(r['avg_time'], 2),
                    "max_time_ms": round(r['max_time'], 2),
                    "errors": r['errors']
                }
                for r in results
            ]
        }
    except psycopg2.Error:
        # í…Œì´ë¸” ì—†ìœ¼ë©´
        return {
            "status": "no_logs",
            "message": "API ë¡œê·¸ í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤"
        }
    finally:
        cur.close()
        conn.close()

def get_error_logs(limit: int = 20) -> dict:
    """ì—ëŸ¬ ë¡œê·¸"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    try:
        query = """
            SELECT 
                id,
                level,
                message,
                stack_trace,
                created_at
            FROM error_logs
            ORDER BY created_at DESC
            LIMIT %s
        """
        
        cur.execute(query, [limit])
        errors = cur.fetchall()
        
        return {
            "count": len(errors),
            "errors": [
                {
                    "id": e['id'],
                    "level": e['level'],
                    "message": e['message'],
                    "timestamp": e['created_at'].isoformat()
                }
                for e in errors
            ]
        }
    except psycopg2.Error:
        return {
            "status": "no_logs",
            "message": "ì—ëŸ¬ ë¡œê·¸ í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤"
        }
    finally:
        cur.close()
        conn.close()

async def main():
    async with stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="tech-monitor-mcp",
                server_version="0.1.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                )
            )
        )

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ”§ Part 4: CEO Checklist MCP

### í´ë” ìƒì„±

```bash
cd "C:\Users\ì„¸ì§„\OneDrive\ë°”íƒ• í™”ë©´\daily-miracles-mvp\mcp-servers"
mkdir ceo-checklist-mcp
cd ceo-checklist-mcp
```

### pyproject.toml

```toml
[project]
name = "ceo-checklist-mcp"
version = "0.1.0"
description = "í‘¸ë¥´ë¯¸ë¥´ ì²´í¬ë¦¬ìŠ¤íŠ¸ MCP"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "mcp>=1.1.2",
    "psycopg2-binary>=2.9.10",
    "python-dotenv>=1.0.0"
]

[project.scripts]
ceo-checklist-mcp = "ceo_checklist_mcp:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

### src/ceo_checklist_mcp/__init__.py

```python
"""
CEO Checklist MCP Server
í‘¸ë¥´ë¯¸ë¥´ ì¼ì¼ ì²´í¬ë¦¬ìŠ¤íŠ¸
"""

import os
import json
from datetime import datetime, timedelta
from typing import Any
import asyncio

import psycopg2
from psycopg2.extras import RealDictCursor
from dotenv import load_dotenv

from mcp.server.models import InitializationOptions
from mcp.server import NotificationOptions, Server
from mcp.server.stdio import stdio_server
from mcp.types import Tool, TextContent

load_dotenv()

def get_db_connection():
    return psycopg2.connect(
        os.getenv("DATABASE_URL"),
        cursor_factory=RealDictCursor
    )

server = Server("ceo-checklist-mcp")

@server.list_tools()
async def handle_list_tools() -> list[Tool]:
    return [
        Tool(
            name="get_daily_checklist",
            description="ì˜¤ëŠ˜ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ìë™ ìƒì„± + ìˆ˜ë™ ì¶”ê°€)",
            inputSchema={
                "type": "object",
                "properties": {
                    "date": {
                        "type": "string",
                        "description": "ë‚ ì§œ (YYYY-MM-DD, ê¸°ë³¸: ì˜¤ëŠ˜)",
                        "default": datetime.now().strftime("%Y-%m-%d")
                    }
                }
            }
        ),
        Tool(
            name="update_checklist_item",
            description="ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª© ì™„ë£Œ ì²˜ë¦¬",
            inputSchema={
                "type": "object",
                "properties": {
                    "item_id": {
                        "type": "number",
                        "description": "í•­ëª© ID"
                    },
                    "completed": {
                        "type": "boolean",
                        "description": "ì™„ë£Œ ì—¬ë¶€",
                        "default": True
                    }
                },
                "required": ["item_id"]
            }
        ),
        Tool(
            name="add_checklist_item",
            description="ì²´í¬ë¦¬ìŠ¤íŠ¸ ìˆ˜ë™ ì¶”ê°€",
            inputSchema={
                "type": "object",
                "properties": {
                    "title": {
                        "type": "string",
                        "description": "í•  ì¼ ì œëª©"
                    },
                    "priority": {
                        "type": "string",
                        "enum": ["P0", "P1", "P2"],
                        "default": "P2"
                    }
                },
                "required": ["title"]
            }
        ),
        Tool(
            name="get_priorities",
            description="ì˜¤ëŠ˜ì˜ ìš°ì„ ìˆœìœ„ ì‘ì—… Top 3",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        )
    ]

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict | None) -> list[TextContent]:
    
    if arguments is None:
        arguments = {}
    
    try:
        if name == "get_daily_checklist":
            result = get_daily_checklist(
                arguments.get("date", datetime.now().strftime("%Y-%m-%d"))
            )
        elif name == "update_checklist_item":
            result = update_checklist_item(
                arguments["item_id"],
                arguments.get("completed", True)
            )
        elif name == "add_checklist_item":
            result = add_checklist_item(
                arguments["title"],
                arguments.get("priority", "P2")
            )
        elif name == "get_priorities":
            result = get_priorities()
        else:
            raise ValueError(f"Unknown tool: {name}")
        
        return [TextContent(
            type="text",
            text=json.dumps(result, ensure_ascii=False, indent=2)
        )]
    except Exception as e:
        return [TextContent(
            type="text",
            text=f"Error: {str(e)}"
        )]

def get_daily_checklist(date_str: str) -> dict:
    """ì¼ì¼ ì²´í¬ë¦¬ìŠ¤íŠ¸"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    # ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ
    query = """
        SELECT 
            id,
            title,
            priority,
            completed,
            completed_at,
            created_at
        FROM ceo_checklist
        WHERE DATE(created_at) = %s
        ORDER BY 
            CASE priority
                WHEN 'P0' THEN 1
                WHEN 'P1' THEN 2
                WHEN 'P2' THEN 3
            END,
            created_at
    """
    
    cur.execute(query, [date_str])
    items = cur.fetchall()
    
    total = len(items)
    completed = sum(1 for i in items if i['completed'])
    completion_rate = (completed / total * 100) if total > 0 else 0
    
    cur.close()
    conn.close()
    
    return {
        "date": date_str,
        "total": total,
        "completed": completed,
        "completion_rate": round(completion_rate, 1),
        "items": [
            {
                "id": i['id'],
                "title": i['title'],
                "priority": i['priority'],
                "completed": i['completed'],
                "completed_at": i['completed_at'].isoformat() if i['completed_at'] else None
            }
            for i in items
        ]
    }

def update_checklist_item(item_id: int, completed: bool) -> dict:
    """ì²´í¬ë¦¬ìŠ¤íŠ¸ ì™„ë£Œ ì²˜ë¦¬"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    query = """
        UPDATE ceo_checklist
        SET 
            completed = %s,
            completed_at = CASE WHEN %s THEN NOW() ELSE NULL END
        WHERE id = %s
        RETURNING id, title, completed
    """
    
    cur.execute(query, [completed, completed, item_id])
    result = cur.fetchone()
    
    conn.commit()
    cur.close()
    conn.close()
    
    if result:
        return {
            "success": True,
            "item": {
                "id": result['id'],
                "title": result['title'],
                "completed": result['completed']
            }
        }
    else:
        return {
            "success": False,
            "message": "í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        }

def add_checklist_item(title: str, priority: str) -> dict:
    """ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¶”ê°€"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    query = """
        INSERT INTO ceo_checklist (title, priority, completed)
        VALUES (%s, %s, FALSE)
        RETURNING id, title, priority
    """
    
    cur.execute(query, [title, priority])
    result = cur.fetchone()
    
    conn.commit()
    cur.close()
    conn.close()
    
    return {
        "success": True,
        "item": {
            "id": result['id'],
            "title": result['title'],
            "priority": result['priority']
        }
    }

def get_priorities() -> dict:
    """ìš°ì„ ìˆœìœ„ Top 3"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    query = """
        SELECT 
            id,
            title,
            priority,
            completed
        FROM ceo_checklist
        WHERE DATE(created_at) = CURRENT_DATE
        AND completed = FALSE
        ORDER BY 
            CASE priority
                WHEN 'P0' THEN 1
                WHEN 'P1' THEN 2
                WHEN 'P2' THEN 3
            END
        LIMIT 3
    """
    
    cur.execute(query)
    items = cur.fetchall()
    
    cur.close()
    conn.close()
    
    return {
        "today": datetime.now().strftime("%Y-%m-%d"),
        "top_3": [
            {
                "id": i['id'],
                "title": i['title'],
                "priority": i['priority']
            }
            for i in items
        ]
    }

async def main():
    async with stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="ceo-checklist-mcp",
                server_version="0.1.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                )
            )
        )

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ”§ Part 5: Dashboard MCP

### í´ë” ìƒì„±

```bash
cd "C:\Users\ì„¸ì§„\OneDrive\ë°”íƒ• í™”ë©´\daily-miracles-mvp\mcp-servers"
mkdir dashboard-mcp
cd dashboard-mcp
```

### pyproject.toml

```toml
[project]
name = "dashboard-mcp"
version = "0.1.0"
description = "í†µí•© ëŒ€ì‹œë³´ë“œ MCP"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "mcp>=1.1.2",
    "psycopg2-binary>=2.9.10",
    "python-dotenv>=1.0.0"
]

[project.scripts]
dashboard-mcp = "dashboard_mcp:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

### src/dashboard_mcp/__init__.py

```python
"""
Dashboard MCP Server
ì „ì²´ í†µí•© ëŒ€ì‹œë³´ë“œ
"""

import os
import json
from datetime import datetime, timedelta
from typing import Any
import asyncio

import psycopg2
from psycopg2.extras import RealDictCursor
from dotenv import load_dotenv

from mcp.server.models import InitializationOptions
from mcp.server import NotificationOptions, Server
from mcp.server.stdio import stdio_server
from mcp.types import Tool, TextContent

load_dotenv()

def get_db_connection():
    return psycopg2.connect(
        os.getenv("DATABASE_URL"),
        cursor_factory=RealDictCursor
    )

server = Server("dashboard-mcp")

@server.list_tools()
async def handle_list_tools() -> list[Tool]:
    return [
        Tool(
            name="get_overview",
            description="ì „ì²´ í˜„í™© í•œëˆˆì— (ëª¨ë“  ì§€í‘œ í†µí•©)",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        ),
        Tool(
            name="get_all_alerts",
            description="ëª¨ë“  ì•Œë¦¼ í†µí•© (ê¸´ê¸‰ë„ ìˆœ)",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        ),
        Tool(
            name="get_insights",
            description="ì¢…í•© ì¸ì‚¬ì´íŠ¸ ë° ì¶”ì²œ ì•¡ì…˜",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        )
    ]

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict | None) -> list[TextContent]:
    
    if arguments is None:
        arguments = {}
    
    try:
        if name == "get_overview":
            result = get_overview()
        elif name == "get_all_alerts":
            result = get_all_alerts()
        elif name == "get_insights":
            result = get_insights()
        else:
            raise ValueError(f"Unknown tool: {name}")
        
        return [TextContent(
            type="text",
            text=json.dumps(result, ensure_ascii=False, indent=2)
        )]
    except Exception as e:
        return [TextContent(
            type="text",
            text=f"Error: {str(e)}"
        )]

def get_overview() -> dict:
    """ì „ì²´ í˜„í™©"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    # ì†Œì›ì´ í†µê³„
    cur.execute("""
        SELECT 
            COUNT(*) as total,
            COUNT(*) FILTER (WHERE status = 'active') as active,
            COUNT(*) FILTER (WHERE last_activity < NOW() - INTERVAL '3 days') as churn_risk
        FROM users
    """)
    users = cur.fetchone()
    
    # ì˜¤ëŠ˜ ë§¤ì¶œ
    cur.execute("""
        SELECT COALESCE(SUM(amount), 0) as today_revenue
        FROM payments
        WHERE DATE(paid_at) = CURRENT_DATE
        AND status = 'completed'
    """)
    revenue = cur.fetchone()
    
    # ì˜¤ëŠ˜ ì‹ ê·œ ê°€ì…
    cur.execute("""
        SELECT COUNT(*) as today_signups
        FROM users
        WHERE DATE(created_at) = CURRENT_DATE
    """)
    signups = cur.fetchone()
    
    # ì˜¤ëŠ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
    cur.execute("""
        SELECT 
            COUNT(*) as total,
            COUNT(*) FILTER (WHERE completed = TRUE) as completed
        FROM ceo_checklist
        WHERE DATE(created_at) = CURRENT_DATE
    """)
    checklist = cur.fetchone()
    
    cur.close()
    conn.close()
    
    return {
        "timestamp": datetime.now().isoformat(),
        "users": {
            "total": users['total'],
            "active": users['active'],
            "churn_risk": users['churn_risk']
        },
        "revenue": {
            "today": revenue['today_revenue']
        },
        "signups": {
            "today": signups['today_signups']
        },
        "checklist": {
            "total": checklist['total'],
            "completed": checklist['completed'],
            "remaining": checklist['total'] - checklist['completed']
        }
    }

def get_all_alerts() -> dict:
    """ëª¨ë“  ì•Œë¦¼"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    alerts = []
    
    # ì´íƒˆ ìœ„í—˜
    cur.execute("""
        SELECT COUNT(*) as count
        FROM users
        WHERE last_activity < NOW() - INTERVAL '3 days'
        AND status = 'active'
    """)
    churn_count = cur.fetchone()['count']
    
    if churn_count > 5:
        alerts.append({
            "priority": "P0",
            "category": "ì´íƒˆ ìœ„í—˜",
            "message": f"ì´íƒˆ ìœ„í—˜ {churn_count}ëª… ê¸‰ì¦",
            "action": "ì¦‰ì‹œ ê°œì… ë©”ì‹œì§€ ë°œì†¡ í•„ìš”"
        })
    
    # ë§¤ì¶œ ì €ì¡°
    cur.execute("""
        SELECT COALESCE(SUM(amount), 0) as today
        FROM payments
        WHERE DATE(paid_at) = CURRENT_DATE
        AND status = 'completed'
    """)
    today_revenue = cur.fetchone()['today']
    
    if today_revenue < 10000:
        alerts.append({
            "priority": "P1",
            "category": "ë§¤ì¶œ",
            "message": f"ì˜¤ëŠ˜ ë§¤ì¶œ {today_revenue:,}ì› (ëª©í‘œ ëŒ€ë¹„ ì €ì¡°)",
            "action": "í”„ë¡œëª¨ì…˜ ê²€í†  í•„ìš”"
        })
    
    # ë¯¸ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸
    cur.execute("""
        SELECT COUNT(*) as count
        FROM ceo_checklist
        WHERE DATE(created_at) = CURRENT_DATE
        AND completed = FALSE
        AND priority = 'P0'
    """)
    p0_remaining = cur.fetchone()['count']
    
    if p0_remaining > 0:
        alerts.append({
            "priority": "P0",
            "category": "ì²´í¬ë¦¬ìŠ¤íŠ¸",
            "message": f"P0 ì‘ì—… {p0_remaining}ê°œ ë¯¸ì™„ë£Œ",
            "action": "ìš°ì„  ì²˜ë¦¬ í•„ìš”"
        })
    
    cur.close()
    conn.close()
    
    # ìš°ì„ ìˆœìœ„ ì •ë ¬
    priority_order = {"P0": 0, "P1": 1, "P2": 2}
    alerts.sort(key=lambda x: priority_order[x['priority']])
    
    return {
        "timestamp": datetime.now().isoformat(),
        "total_alerts": len(alerts),
        "alerts": alerts
    }

def get_insights() -> dict:
    """ì¢…í•© ì¸ì‚¬ì´íŠ¸"""
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    insights = []
    recommendations = []
    
    # ì „í™˜ìœ¨ ë¶„ì„
    cur.execute("""
        SELECT 
            COUNT(*) as total_users,
            COUNT(*) FILTER (WHERE EXISTS (
                SELECT 1 FROM payments WHERE payments.user_id = users.id
            )) as paid_users
        FROM users
        WHERE created_at >= NOW() - INTERVAL '30 days'
    """)
    conversion = cur.fetchone()
    
    if conversion['total_users'] > 0:
        rate = conversion['paid_users'] / conversion['total_users'] * 100
        insights.append({
            "category": "ì „í™˜ìœ¨",
            "metric": f"{rate:.1f}%",
            "trend": "ìƒìŠ¹" if rate > 5 else "í•˜ë½",
            "description": f"ìµœê·¼ 30ì¼ ì „í™˜ìœ¨ {rate:.1f}%"
        })
        
        if rate < 5:
            recommendations.append({
                "priority": "P1",
                "action": "ì „í™˜ìœ¨ ê°œì„  ìº í˜ì¸ í•„ìš”",
                "expected_impact": "ì „í™˜ìœ¨ 2ë°° ëª©í‘œ"
            })
    
    # í™œì„± ì‚¬ìš©ì ì¶”ì´
    cur.execute("""
        SELECT COUNT(*) as active_count
        FROM users
        WHERE last_activity >= NOW() - INTERVAL '7 days'
    """)
    active = cur.fetchone()['active_count']
    
    insights.append({
        "category": "í™œì„± ì‚¬ìš©ì",
        "metric": f"{active}ëª…",
        "trend": "ì•ˆì •",
        "description": "7ì¼ ë‚´ í™œë™ ì‚¬ìš©ì"
    })
    
    cur.close()
    conn.close()
    
    return {
        "timestamp": datetime.now().isoformat(),
        "insights": insights,
        "recommendations": recommendations
    }

async def main():
    async with stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="dashboard-mcp",
                server_version="0.1.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                )
            )
        )

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ“ DB ìŠ¤í‚¤ë§ˆ ì¶”ê°€ (í•„ìš”ì‹œ)

### SQL ìŠ¤í¬ë¦½íŠ¸

```sql
-- CEO ì²´í¬ë¦¬ìŠ¤íŠ¸ í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS ceo_checklist (
    id SERIAL PRIMARY KEY,
    title TEXT NOT NULL,
    priority VARCHAR(3) DEFAULT 'P2',
    completed BOOLEAN DEFAULT FALSE,
    completed_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW()
);

-- API ë¡œê·¸ í…Œì´ë¸” (ì„ íƒ)
CREATE TABLE IF NOT EXISTS api_logs (
    id SERIAL PRIMARY KEY,
    endpoint TEXT,
    method VARCHAR(10),
    status_code INTEGER,
    response_time FLOAT,
    created_at TIMESTAMP DEFAULT NOW()
);

-- ì—ëŸ¬ ë¡œê·¸ í…Œì´ë¸” (ì„ íƒ)
CREATE TABLE IF NOT EXISTS error_logs (
    id SERIAL PRIMARY KEY,
    level VARCHAR(20),
    message TEXT,
    stack_trace TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);

-- êµ¬ë… í…Œì´ë¸” (ê¸°ì¡´ì— ì—†ìœ¼ë©´)
CREATE TABLE IF NOT EXISTS subscriptions (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    plan_type VARCHAR(50),
    status VARCHAR(20),
    start_date DATE,
    end_date DATE,
    auto_renew BOOLEAN DEFAULT FALSE,
    monthly_fee NUMERIC(10, 2),
    created_at TIMESTAMP DEFAULT NOW()
);
```

---

## ğŸ”„ claude_desktop_config.json ì—…ë°ì´íŠ¸

```json
{
  "mcpServers": {
    "miracle-mcp": {
      "command": "uv",
      "args": [
        "--directory",
        "C:\\Users\\ì„¸ì§„\\OneDrive\\ë°”íƒ• í™”ë©´\\daily-miracles-mvp\\mcp-servers\\miracle-mcp",
        "run",
        "miracle-mcp"
      ]
    },
    "wishmaker-hub-mcp": {
      "command": "uv",
      "args": [
        "--directory",
        "C:\\Users\\ì„¸ì§„\\OneDrive\\ë°”íƒ• í™”ë©´\\daily-miracles-mvp\\mcp-servers\\wishmaker-hub-mcp",
        "run",
        "wishmaker-hub-mcp"
      ]
    },
    "summarizer-mcp": {
      "command": "uv",
      "args": [
        "--directory",
        "C:\\Users\\ì„¸ì§„\\OneDrive\\ë°”íƒ• í™”ë©´\\daily-miracles-mvp\\mcp-servers\\summarizer-mcp",
        "run",
        "summarizer-mcp"
      ]
    },
    "business-ops-mcp": {
      "command": "uv",
      "args": [
        "--directory",
        "C:\\Users\\ì„¸ì§„\\OneDrive\\ë°”íƒ• í™”ë©´\\daily-miracles-mvp\\mcp-servers\\business-ops-mcp",
        "run",
        "business-ops-mcp"
      ]
    },
    "tech-monitor-mcp": {
      "command": "uv",
      "args": [
        "--directory",
        "C:\\Users\\ì„¸ì§„\\OneDrive\\ë°”íƒ• í™”ë©´\\daily-miracles-mvp\\mcp-servers\\tech-monitor-mcp",
        "run",
        "tech-monitor-mcp"
      ]
    },
    "ceo-checklist-mcp": {
      "command": "uv",
      "args": [
        "--directory",
        "C:\\Users\\ì„¸ì§„\\OneDrive\\ë°”íƒ• í™”ë©´\\daily-miracles-mvp\\mcp-servers\\ceo-checklist-mcp",
        "run",
        "ceo-checklist-mcp"
      ]
    },
    "dashboard-mcp": {
      "command": "uv",
      "args": [
        "--directory",
        "C:\\Users\\ì„¸ì§„\\OneDrive\\ë°”íƒ• í™”ë©´\\daily-miracles-mvp\\mcp-servers\\dashboard-mcp",
        "run",
        "dashboard-mcp"
      ]
    }
  }
}
```

---

## âœ… ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

### Day 1
```
â–¡ business-ops-mcp í´ë” ìƒì„±
â–¡ pyproject.toml ì‘ì„±
â–¡ __init__.py ì‘ì„±
â–¡ uv sync ì‹¤í–‰
â–¡ í…ŒìŠ¤íŠ¸ (uv run business-ops-mcp)
â–¡ Desktop ì—°ë™
â–¡ ë„êµ¬ í…ŒìŠ¤íŠ¸:
  â–¡ get_payments
  â–¡ get_revenue
  â–¡ get_subscriptions
  â–¡ get_revenue_forecast
```

### Day 2
```
â–¡ tech-monitor-mcp ì™„ì„±
  â–¡ check_server_status
  â–¡ check_db_health
  â–¡ check_api_performance
  â–¡ get_error_logs

â–¡ ceo-checklist-mcp ì™„ì„±
  â–¡ get_daily_checklist
  â–¡ update_checklist_item
  â–¡ add_checklist_item
  â–¡ get_priorities

â–¡ DB ìŠ¤í‚¤ë§ˆ ì¶”ê°€
â–¡ Desktop ì—°ë™
```

### Day 3
```
â–¡ dashboard-mcp ì™„ì„±
  â–¡ get_overview
  â–¡ get_all_alerts
  â–¡ get_insights

â–¡ claude_desktop_config.json ìµœì¢… ì—…ë°ì´íŠ¸
â–¡ ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸
â–¡ ë¬¸ì„œ ì‘ì„±
â–¡ 100% ì™„ì„±! ğŸ‰
```

---

## ğŸš€ ì‹œì‘ ëª…ë ¹ì–´

```bash
# Part 2
cd "C:\Users\ì„¸ì§„\OneDrive\ë°”íƒ• í™”ë©´\daily-miracles-mvp\mcp-servers"
mkdir business-ops-mcp
cd business-ops-mcp
# (ìœ„ íŒŒì¼ë“¤ ìƒì„±)
uv sync
uv run business-ops-mcp  # í…ŒìŠ¤íŠ¸

# Part 3
cd ..
mkdir tech-monitor-mcp
# (ë°˜ë³µ)

# Part 4
cd ..
mkdir ceo-checklist-mcp
# (ë°˜ë³µ)

# Part 5
cd ..
mkdir dashboard-mcp
# (ë°˜ë³µ)
```

---

## ğŸ’¬ í…ŒìŠ¤íŠ¸ ë°©ë²•

### Desktopì—ì„œ í…ŒìŠ¤íŠ¸

```
# Part 2
ì˜¤ëŠ˜ ê²°ì œ ë‚´ì—­ ë³´ì—¬ì¤˜
@business-ops-mcp get_payments days=1

ìµœê·¼ 30ì¼ ë§¤ì¶œ ë¶„ì„í•´ì¤˜
@business-ops-mcp get_revenue period="daily" days=30

# Part 3
ì„œë²„ ìƒíƒœ í™•ì¸í•´ì¤˜
@tech-monitor-mcp check_server_status

DB ê±´ê°•ë„ ì²´í¬í•´ì¤˜
@tech-monitor-mcp check_db_health

# Part 4
ì˜¤ëŠ˜ í•  ì¼ ë­ì•¼?
@ceo-checklist-mcp get_daily_checklist

ìš°ì„ ìˆœìœ„ Top 3ëŠ”?
@ceo-checklist-mcp get_priorities

# Part 5
ì „ì²´ í˜„í™© ë³´ì—¬ì¤˜
@dashboard-mcp get_overview

ëª¨ë“  ì•Œë¦¼ í™•ì¸í•´ì¤˜
@dashboard-mcp get_all_alerts
```

---

## ğŸ‰ ì™„ì„± í›„

**MCP 100% ë‹¬ì„±!**

```
âœ… Part 1: ì†Œì›ì´ í†µí•© ê´€ë¦¬ (33%)
âœ… Part 2: ë¹„ì¦ˆë‹ˆìŠ¤ ìš´ì˜ (20%)
âœ… Part 3: ê¸°ìˆ  ì¸í”„ë¼ (17%)
âœ… Part 4: CEO ì²´í¬ë¦¬ìŠ¤íŠ¸ (15%)
âœ… Part 5: í†µí•© ëŒ€ì‹œë³´ë“œ (15%)

= 100% ì™„ì„±! ğŸ‰
```

**ë‹¤ìŒ ë‹¨ê³„:**
Aurora 5 Ultimate ì‹œì‘! ğŸš€

---

**ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•˜ì„¸ìš”!**

Codeì•¼, Part 2ë¶€í„° ì‹œì‘! ğŸ’ª